{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinayak-Sharma12/Toxic-Comment-Classifier/blob/main/Toxic_Comment_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTING IMPORTANT LIBRARIES**"
      ],
      "metadata": {
        "id": "aC8ZzdaZQV2X"
      },
      "id": "aC8ZzdaZQV2X"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8740f85f",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-08-31T13:52:16.252150Z",
          "iopub.status.busy": "2023-08-31T13:52:16.251809Z",
          "iopub.status.idle": "2023-08-31T13:53:00.566118Z",
          "shell.execute_reply": "2023-08-31T13:53:00.564994Z"
        },
        "papermill": {
          "duration": 44.338917,
          "end_time": "2023-08-31T13:53:00.569046",
          "exception": false,
          "start_time": "2023-08-31T13:52:16.230129",
          "status": "completed"
        },
        "tags": [],
        "id": "8740f85f"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers import Embedding\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics\n",
        "from keras.preprocessing import sequence, text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "By32gdJxPy3g"
      },
      "id": "By32gdJxPy3g"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "31235c50",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:09.076537Z",
          "iopub.status.busy": "2023-08-31T13:53:09.076239Z",
          "iopub.status.idle": "2023-08-31T13:53:12.870122Z",
          "shell.execute_reply": "2023-08-31T13:53:12.868901Z"
        },
        "papermill": {
          "duration": 3.820569,
          "end_time": "2023-08-31T13:53:12.872901",
          "exception": false,
          "start_time": "2023-08-31T13:53:09.052332",
          "status": "completed"
        },
        "tags": [],
        "id": "31235c50"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/train (3).csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8b36bb5",
      "metadata": {
        "papermill": {
          "duration": 0.024356,
          "end_time": "2023-08-31T13:53:12.920840",
          "exception": false,
          "start_time": "2023-08-31T13:53:12.896484",
          "status": "completed"
        },
        "tags": [],
        "id": "c8b36bb5"
      },
      "source": [
        "We will drop the other columns and approach this problem as a Binary Classification Problem and also we will have our exercise done on a smaller subsection of the dataset(only 12000 data points) to make it easier to train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d976ac49",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:12.969453Z",
          "iopub.status.busy": "2023-08-31T13:53:12.969096Z",
          "iopub.status.idle": "2023-08-31T13:53:12.988493Z",
          "shell.execute_reply": "2023-08-31T13:53:12.987451Z"
        },
        "papermill": {
          "duration": 0.046357,
          "end_time": "2023-08-31T13:53:12.991028",
          "exception": false,
          "start_time": "2023-08-31T13:53:12.944671",
          "status": "completed"
        },
        "tags": [],
        "id": "d976ac49"
      },
      "outputs": [],
      "source": [
        "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "31973979",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:13.040405Z",
          "iopub.status.busy": "2023-08-31T13:53:13.040062Z",
          "iopub.status.idle": "2023-08-31T13:53:13.047627Z",
          "shell.execute_reply": "2023-08-31T13:53:13.046780Z"
        },
        "papermill": {
          "duration": 0.034349,
          "end_time": "2023-08-31T13:53:13.049655",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.015306",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31973979",
        "outputId": "fd40c43e-9072-44df-8788-d1e807752f1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12001, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train = train.loc[:12000,:]\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ad44af",
      "metadata": {
        "papermill": {
          "duration": 0.022937,
          "end_time": "2023-08-31T13:53:13.095914",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.072977",
          "status": "completed"
        },
        "tags": [],
        "id": "17ad44af"
      },
      "source": [
        "We will check the maximum number of words that can be present in a comment , this will help us in padding later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fa372efa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:13.146339Z",
          "iopub.status.busy": "2023-08-31T13:53:13.145467Z",
          "iopub.status.idle": "2023-08-31T13:53:13.231584Z",
          "shell.execute_reply": "2023-08-31T13:53:13.230609Z"
        },
        "papermill": {
          "duration": 0.114973,
          "end_time": "2023-08-31T13:53:13.233928",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.118955",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa372efa",
        "outputId": "df30cc74-fe74-4614-a096-a017c7d95e36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1403"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train['comment_text'].apply(lambda x:len(str(x).split())).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c601bad3",
      "metadata": {
        "papermill": {
          "duration": 0.024938,
          "end_time": "2023-08-31T13:53:13.284101",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.259163",
          "status": "completed"
        },
        "tags": [],
        "id": "c601bad3"
      },
      "source": [
        "Writing a function for getting auc score for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "467d5e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:13.334952Z",
          "iopub.status.busy": "2023-08-31T13:53:13.334074Z",
          "iopub.status.idle": "2023-08-31T13:53:13.340159Z",
          "shell.execute_reply": "2023-08-31T13:53:13.339118Z"
        },
        "papermill": {
          "duration": 0.034331,
          "end_time": "2023-08-31T13:53:13.342349",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.308018",
          "status": "completed"
        },
        "tags": [],
        "id": "467d5e66"
      },
      "outputs": [],
      "source": [
        "def roc_auc(predictions,target):\n",
        "    '''\n",
        "    This methods returns the AUC Score when given the Predictions\n",
        "    and Labels\n",
        "    '''\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11bc3dcf",
      "metadata": {
        "papermill": {
          "duration": 0.022384,
          "end_time": "2023-08-31T13:53:13.388027",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.365643",
          "status": "completed"
        },
        "tags": [],
        "id": "11bc3dcf"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cf73b9d5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:13.434984Z",
          "iopub.status.busy": "2023-08-31T13:53:13.434710Z",
          "iopub.status.idle": "2023-08-31T13:53:13.444991Z",
          "shell.execute_reply": "2023-08-31T13:53:13.444156Z"
        },
        "papermill": {
          "duration": 0.03655,
          "end_time": "2023-08-31T13:53:13.447167",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.410617",
          "status": "completed"
        },
        "tags": [],
        "id": "cf73b9d5"
      },
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values,\n",
        "                                                  stratify=train.toxic.values,\n",
        "                                                  random_state=42,\n",
        "                                                  test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "277f25cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:13.540400Z",
          "iopub.status.busy": "2023-08-31T13:53:13.539624Z",
          "iopub.status.idle": "2023-08-31T13:53:15.444541Z",
          "shell.execute_reply": "2023-08-31T13:53:15.443427Z"
        },
        "papermill": {
          "duration": 1.931922,
          "end_time": "2023-08-31T13:53:15.447136",
          "exception": false,
          "start_time": "2023-08-31T13:53:13.515214",
          "status": "completed"
        },
        "tags": [],
        "id": "277f25cb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 1500\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "#zero pad the sequences\n",
        "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL TRAINING**"
      ],
      "metadata": {
        "id": "yQB48_XWQ56m"
      },
      "id": "yQB48_XWQ56m"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "560371d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:15.494703Z",
          "iopub.status.busy": "2023-08-31T13:53:15.494343Z",
          "iopub.status.idle": "2023-08-31T13:53:18.043188Z",
          "shell.execute_reply": "2023-08-31T13:53:18.042174Z"
        },
        "papermill": {
          "duration": 2.577475,
          "end_time": "2023-08-31T13:53:18.047721",
          "exception": false,
          "start_time": "2023-08-31T13:53:15.470246",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560371d8",
        "outputId": "1a851923-9cd7-4718-d942-b85eea3bbfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1500, 300)         13049100  \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 100)               40100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13089301 (49.93 MB)\n",
            "Trainable params: 13089301 (49.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "CPU times: user 118 ms, sys: 3.75 ms, total: 122 ms\n",
            "Wall time: 123 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with strategy.scope():\n",
        "    # A simpleRNN without any pretrained embeddings and one dense layer\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(len(word_index) + 1,\n",
        "                     300,\n",
        "                     input_length=max_len))\n",
        "    model.add(SimpleRNN(100))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ee564861",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:18.097772Z",
          "iopub.status.busy": "2023-08-31T13:53:18.097475Z",
          "iopub.status.idle": "2023-08-31T13:53:39.202310Z",
          "shell.execute_reply": "2023-08-31T13:53:39.201190Z"
        },
        "papermill": {
          "duration": 21.132743,
          "end_time": "2023-08-31T13:53:39.204808",
          "exception": false,
          "start_time": "2023-08-31T13:53:18.072065",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee564861",
        "outputId": "d5610a42-5301-4c6e-da37-0b27a50fc9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "150/150 [==============================] - 192s 1s/step - loss: 0.6662 - accuracy: 0.8952\n",
            "Epoch 2/3\n",
            "150/150 [==============================] - 189s 1s/step - loss: 0.5927 - accuracy: 0.9279\n",
            "Epoch 3/3\n",
            "150/150 [==============================] - 185s 1s/step - loss: 0.5023 - accuracy: 0.9476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f14b983790>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=3, batch_size=64*strategy.num_replicas_in_sync)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xtrain_pad, ytrain, epochs=2, batch_size=64*strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ilYbMpIIwu0",
        "outputId": "81f25851-0cb4-4774-ab8c-c125e8ad1fbd"
      },
      "id": "5ilYbMpIIwu0",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "150/150 [==============================] - 184s 1s/step - loss: 0.5169 - accuracy: 0.9580\n",
            "Epoch 2/2\n",
            "150/150 [==============================] - 182s 1s/step - loss: 0.5117 - accuracy: 0.9607\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f120f00d60>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACCURACY**"
      ],
      "metadata": {
        "id": "0gr5QEfVRB-n"
      },
      "id": "0gr5QEfVRB-n"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "3177e527",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:39.276877Z",
          "iopub.status.busy": "2023-08-31T13:53:39.276498Z",
          "iopub.status.idle": "2023-08-31T13:53:42.620201Z",
          "shell.execute_reply": "2023-08-31T13:53:42.618917Z"
        },
        "papermill": {
          "duration": 3.381587,
          "end_time": "2023-08-31T13:53:42.622738",
          "exception": false,
          "start_time": "2023-08-31T13:53:39.241151",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3177e527",
        "outputId": "24192ae6-55e1-456e-fa11-596486068e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76/76 [==============================] - 8s 103ms/step\n",
            "Auc: 0.78%\n"
          ]
        }
      ],
      "source": [
        "scores = model.predict(xvalid_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bdcc864e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-31T13:53:42.703319Z",
          "iopub.status.busy": "2023-08-31T13:53:42.702908Z",
          "iopub.status.idle": "2023-08-31T13:53:42.710668Z",
          "shell.execute_reply": "2023-08-31T13:53:42.709615Z"
        },
        "papermill": {
          "duration": 0.052095,
          "end_time": "2023-08-31T13:53:42.712903",
          "exception": false,
          "start_time": "2023-08-31T13:53:42.660808",
          "status": "completed"
        },
        "tags": [],
        "id": "bdcc864e"
      },
      "outputs": [],
      "source": [
        "scores_model = []\n",
        "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores,yvalid)})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREDICTION**"
      ],
      "metadata": {
        "id": "ebFgB06CRINw"
      },
      "id": "ebFgB06CRINw"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming `model` is your trained model\n",
        "# Assuming `tokenizer` is the tokenizer you used for preprocessing your text data\n",
        "\n",
        "# Text to predict\n",
        "text1 = \"you bastard\"\n",
        "text2=\"I like your confindence\"\n",
        "text3=\"You are a bitch\"\n",
        "text4=\"I appreciate your behaviour\"\n",
        "text5=\"You are a peice of a shit\"\n",
        "text6=\"I mean look how adorable you are\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_text1= token.texts_to_sequences([text1])\n",
        "tokenized_text2= token.texts_to_sequences([text2])\n",
        "tokenized_text3 = token.texts_to_sequences([text3])\n",
        "tokenized_text4 = token.texts_to_sequences([text4])\n",
        "tokenized_text5 = token.texts_to_sequences([text5])\n",
        "tokenized_text6 = token.texts_to_sequences([text6])\n",
        "\n",
        "# Pad sequences to a fixed length (if necessary)\n",
        "max_sequence_length = 100  # Example sequence length\n",
        "padded_sequence1 = pad_sequences(tokenized_text1, maxlen=max_sequence_length)\n",
        "padded_sequence2 = pad_sequences(tokenized_text2, maxlen=max_sequence_length)\n",
        "padded_sequence3 = pad_sequences(tokenized_text3, maxlen=max_sequence_length)\n",
        "padded_sequence4 = pad_sequences(tokenized_text4, maxlen=max_sequence_length)\n",
        "padded_sequence5 = pad_sequences(tokenized_text5, maxlen=max_sequence_length)\n",
        "padded_sequence6 = pad_sequences(tokenized_text6, maxlen=max_sequence_length)\n",
        "\n",
        "# Make predictions\n",
        "predictions1 = model.predict(padded_sequence1)\n",
        "predictions2 = model.predict(padded_sequence2)\n",
        "predictions3 = model.predict(padded_sequence3)\n",
        "predictions4 = model.predict(padded_sequence4)\n",
        "predictions5 = model.predict(padded_sequence5)\n",
        "predictions6 = model.predict(padded_sequence6)\n",
        "if predictions1>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n",
        "if predictions2>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n",
        "if predictions3>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n",
        "if predictions4>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n",
        "if predictions5>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n",
        "if predictions6>0.5:\n",
        "   print('Toxic')\n",
        "else:\n",
        "  print('Not Toxic')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEOyP7OFLHty",
        "outputId": "fef2d345-b669-4d6d-95a2-93062261bbc3"
      },
      "id": "jEOyP7OFLHty",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Toxic\n",
            "Not Toxic\n",
            "Toxic\n",
            "Not Toxic\n",
            "Toxic\n",
            "Not Toxic\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 462.879437,
      "end_time": "2023-08-31T13:59:34.088078",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-08-31T13:51:51.208641",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}